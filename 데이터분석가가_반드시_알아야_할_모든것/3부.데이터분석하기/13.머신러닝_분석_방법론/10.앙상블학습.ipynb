{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33            184.6   \n",
       "1                 0.05667  ...         24.99          23.41            158.8   \n",
       "2                 0.05999  ...         23.57          25.53            152.5   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "\n",
    "data_df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "data_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> VotingClassifier 클래스는 주요 생성 인자로 estimators와 voting 값을 입력받음. \n",
    "> estimators는 리스트 값으로 보팅에 사용될 여러 개의 Classifier 객체들을 튜플 형식으로 입력받으며 voting은 'hard'(하드보팅), 'soft'(소프트보팅) 중 보팅 방식을 적용하라는 의미(기본값 = hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting 분류기 정확도: 0.9561\n",
      "LogisticRegression정확도: 0.9474\n",
      "KNeighborsClassifier정확도: 0.9386\n"
     ]
    }
   ],
   "source": [
    "# 개별 모델은 로지스틱 회귀와 KNN임.\n",
    "lr_clf = LogisticRegression(solver='liblinear')\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=8)\n",
    "\n",
    "# 개별 모델을 소프트 보팅 기반의 앙상블 모델로 구현한 분류기\n",
    "vo_clf = VotingClassifier(estimators=[('LR', lr_clf),('KNN', knn_clf)], voting='soft')\n",
    "x_train, x_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.2, random_state=156)\n",
    "\n",
    "# VotingClassifier 학습/예측/평가.\n",
    "vo_clf.fit(x_train, y_train)\n",
    "pred = vo_clf.predict(x_test)\n",
    "print('Voting 분류기 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))\n",
    "\n",
    "# 개별 모델의 학습/예측/평가\n",
    "classifiers = [lr_clf, knn_clf]\n",
    "for classifier in classifiers:\n",
    "    classifier.fit(x_train, y_train)\n",
    "    pred = classifier.predict(x_test)\n",
    "    class_name = classifier.__class__.__name__\n",
    "    print('{0}정확도: {1:.4f}'.format(class_name, accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> LogisticRegression parameters : solver\n",
    "\n",
    "|구분|설명|\n",
    "|--|--|\n",
    "|||"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 보팅 분류기가 정확도가 조금 높게 나왔지만, 보팅으로 여러 개의 분류기를 결합한다고 해서 무조건 기반 분류기 보다 예측 성능이 향상되지는 않는다. 데이터의 특성과 분포 등 다양한 요건에 따라 오히려 기반 분류기 중 가장 좋은 분류기의 성능이 보팅했을 때보다 나을 수도 있다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> n_estimators : 랜덤포레스트에서 결정트리의 개수 지정. 디폴트는 10개. 많이 설정할수록 좋은 성능을 기대할 수 있지만 계속 증가시킨다고 성능이 무조건 향상되는 것은 아니다. 또한 늘릴 수록 학습 수행 시간이 오래 걸림.\n",
    "\n",
    "> max_features : 결정트리에 사용된 max_features파라미터와 같음. 하지만 RandomForestClassifier의 기본 max_features는 'None'이 아니라 'auto'즉, 'sqrt'와 같다. 따라서 랜덤포레스트의 트리를 분할하는 피처를 참조할 때 전체 피처가 아니라 sqrt(전체피처개수)만큼 참조\n",
    "\n",
    "> max_depth, min_samples_leaf, min_samples_split와 같이 결정트리에서 과적합을 개선하기 위해 사용되는 파라미터가 랜덤포레스트에 똑같이 적용. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하이퍼 파라미터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = { 'max_depth': [8,16,24],\n",
    "#           'min_samples_split':[2,8,16]\n",
    "#           'min_samples_leaf':[1,6,12]}\n",
    "\n",
    "# # RandomForestClassifier객체 생성 후 GridSearchCV 수행\n",
    "# rf_clf = RandomForestClassifier(n_estimators=100, random_state=0, n_jobs=-1)\n",
    "# grid_cv = GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
    "# grid_cv.fit(x_train, x_test)\n",
    "\n",
    "# print('최적 하이퍼 파라미터:', grid_cv.best_params_)\n",
    "# print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적의 하이퍼 파라미터를 가지고 RandomForestClassifier 실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_clf1 = RandomForestClassifier(n_estimators=100, min_samples_leaf=6, max_depth=16, min_samples_split=2, random_state=0)\n",
    "# rf_clf1.fit(x_train, y_train)\n",
    "# pred = rf_clf1.predict(x_test)\n",
    "# print('예측정확도:{0:.4f}'.format(accuracy_score(y_test, pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### feature_importances_ 속성을 이용해 피처의 중요도 확인가능\n",
    "\n",
    "> RandomForestClassifier 역시 DecisionTreeClassifier와 같이 feature_importances_속성을 이용해 알고리즘이 선택한 피처의 정확도 확인 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sb\n",
    "# %matplotlib inline\n",
    "\n",
    "# ftr_importance_values = rf_clf1.feature_importances_\n",
    "# ftr_importances = pd.Series(ftr_importance_values, index=x_train.columns)\n",
    "# ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# plt.title('Feature importances Top 20')\n",
    "# sb.barplot(x=ftr_top20, y=ftr_top20.index)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM (GradientBoostingClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# import time\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# x_train, x_test, y_train, y_test = get_human_dataset()\n",
    "\n",
    "# # GBM 수행시간 측정을 위함. 시작 시간 설정.\n",
    "# start_time = time.time()\n",
    "\n",
    "# gb_clf = GradientBoostingClassifier(random_state=0)\n",
    "# gb_clf.fit(x_train, y_train)\n",
    "# gb_pred = gb_clf.predict(x_test)\n",
    "# gb_accuracy = accuracy_score(y_test, pred)\n",
    "\n",
    "# print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
    "# print('GBM 수행시간:{0.1f}초'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|파라미터|설명|\n",
    "|---|---|\n",
    "|loss|경사하강법에서 사용할 비용함수를 지정. 특별한 이유가 없으면 기본값인 'deviance'사용|\n",
    "|learning_rate|GBM이 학습을 진행할 때마다 적용하는 학습률. 약한 분류기가 순차적으로 오류값을 보정해 나가는데 적용하는 계수. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost(eXtra Gradient Boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.8</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.6</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.9</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.8</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.5</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38           122.8     1001.0          0.11840   \n",
       "1        20.57         17.77           132.9     1326.0          0.08474   \n",
       "2        19.69         21.25           130.0     1203.0          0.10960   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33            184.6      2019.0   \n",
       "1                 0.05667  ...          23.41            158.8      1956.0   \n",
       "2                 0.05999  ...          25.53            152.5      1709.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_breast_cancer()\n",
    "features = dataset.data\n",
    "labels = dataset.target\n",
    "\n",
    "cancer_df = pd.DataFrame(data=features, columns=dataset.feature_names)\n",
    "cancer_df['target'] = labels\n",
    "cancer_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 악성('malignant'):0, 양성('benign'):1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.target_names)\n",
    "print(cancer_df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30)\n",
      "(409, 30) (46, 30)\n"
     ]
    }
   ],
   "source": [
    "# cancer_df 에서 feature용 DataFrame과 Label용 Series 객체 추출\n",
    "# 맨 마지막 칼럼이 Label임. Feature용 DataFrame은 cancer_df의 첫번째 칼럼에서 맨 마지막 두번째 칼럼까지를 :-1슬라이싱으로 추출.\n",
    "x_features = cancer_df.iloc[:, :-1]\n",
    "y_label = cancer_df.iloc[:,-1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_label, test_size=0.2, random_state=156)\n",
    "\n",
    "# 위에서 만든 x_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=156)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_tr.shape, x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습데이터의 학습용\n",
    "dtr = xgb.DMatrix(data=x_tr, label=y_tr)\n",
    "# 학습데이터의 검증용\n",
    "dval = xgb.DMatrix(data=x_val, label=y_val)\n",
    "# 검증데이터\n",
    "dtest = xgb.DMatrix(data=x_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 설정\n",
    "params = {'max_depth':3, \n",
    "          'eta':0.05, # =learning_rate\n",
    "          'objective':'binary:logistic', # 종속변수가 이진분류이므로 binary logistic\n",
    "          'eval_metric':'logloss'} # 오류함수 평가 성능 지표는 logloss\n",
    "\n",
    "num_rounds = 400 # 부스팅반복횟수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|xgboost|XGBoostClassifier|\n",
    "|--|--|\n",
    "|'eta'|'learning_rate'|\n",
    "|'sub_sample'|subsample|\n",
    "|lambda|reg_lambda|\n",
    "|alpha|reg_alpha|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.62480\teval-logloss:0.63104\n",
      "[1]\ttrain-logloss:0.58674\teval-logloss:0.60478\n",
      "[2]\ttrain-logloss:0.55226\teval-logloss:0.58223\n",
      "[3]\ttrain-logloss:0.52086\teval-logloss:0.56184\n",
      "[4]\ttrain-logloss:0.49192\teval-logloss:0.54118\n",
      "[5]\ttrain-logloss:0.46537\teval-logloss:0.52223\n",
      "[6]\ttrain-logloss:0.44029\teval-logloss:0.50287\n",
      "[7]\ttrain-logloss:0.41666\teval-logloss:0.48620\n",
      "[8]\ttrain-logloss:0.39525\teval-logloss:0.46974\n",
      "[9]\ttrain-logloss:0.37542\teval-logloss:0.45497\n",
      "[10]\ttrain-logloss:0.35701\teval-logloss:0.44131\n",
      "[11]\ttrain-logloss:0.33982\teval-logloss:0.43134\n",
      "[12]\ttrain-logloss:0.32297\teval-logloss:0.41972\n",
      "[13]\ttrain-logloss:0.30725\teval-logloss:0.40902\n",
      "[14]\ttrain-logloss:0.29327\teval-logloss:0.39883\n",
      "[15]\ttrain-logloss:0.27946\teval-logloss:0.38968\n",
      "[16]\ttrain-logloss:0.26691\teval-logloss:0.38150\n",
      "[17]\ttrain-logloss:0.25473\teval-logloss:0.37368\n",
      "[18]\ttrain-logloss:0.24385\teval-logloss:0.36666\n",
      "[19]\ttrain-logloss:0.23338\teval-logloss:0.35994\n",
      "[20]\ttrain-logloss:0.22320\teval-logloss:0.35374\n",
      "[21]\ttrain-logloss:0.21363\teval-logloss:0.34704\n",
      "[22]\ttrain-logloss:0.20487\teval-logloss:0.34206\n",
      "[23]\ttrain-logloss:0.19634\teval-logloss:0.33621\n",
      "[24]\ttrain-logloss:0.18830\teval-logloss:0.33178\n",
      "[25]\ttrain-logloss:0.18093\teval-logloss:0.32774\n",
      "[26]\ttrain-logloss:0.17374\teval-logloss:0.32297\n",
      "[27]\ttrain-logloss:0.16695\teval-logloss:0.31855\n",
      "[28]\ttrain-logloss:0.16059\teval-logloss:0.31495\n",
      "[29]\ttrain-logloss:0.15450\teval-logloss:0.31173\n",
      "[30]\ttrain-logloss:0.14875\teval-logloss:0.30735\n",
      "[31]\ttrain-logloss:0.14329\teval-logloss:0.30463\n",
      "[32]\ttrain-logloss:0.13807\teval-logloss:0.30242\n",
      "[33]\ttrain-logloss:0.13325\teval-logloss:0.29922\n",
      "[34]\ttrain-logloss:0.12864\teval-logloss:0.29722\n",
      "[35]\ttrain-logloss:0.12429\teval-logloss:0.29540\n",
      "[36]\ttrain-logloss:0.12000\teval-logloss:0.29300\n",
      "[37]\ttrain-logloss:0.11581\teval-logloss:0.29010\n",
      "[38]\ttrain-logloss:0.11210\teval-logloss:0.28883\n",
      "[39]\ttrain-logloss:0.10838\teval-logloss:0.28769\n",
      "[40]\ttrain-logloss:0.10481\teval-logloss:0.28574\n",
      "[41]\ttrain-logloss:0.10160\teval-logloss:0.28434\n",
      "[42]\ttrain-logloss:0.09832\teval-logloss:0.28226\n",
      "[43]\ttrain-logloss:0.09534\teval-logloss:0.28006\n",
      "[44]\ttrain-logloss:0.09249\teval-logloss:0.27854\n",
      "[45]\ttrain-logloss:0.08972\teval-logloss:0.27747\n",
      "[46]\ttrain-logloss:0.08700\teval-logloss:0.27654\n",
      "[47]\ttrain-logloss:0.08461\teval-logloss:0.27598\n",
      "[48]\ttrain-logloss:0.08225\teval-logloss:0.27415\n",
      "[49]\ttrain-logloss:0.08001\teval-logloss:0.27245\n",
      "[50]\ttrain-logloss:0.07784\teval-logloss:0.27104\n",
      "[51]\ttrain-logloss:0.07578\teval-logloss:0.26958\n",
      "[52]\ttrain-logloss:0.07384\teval-logloss:0.26869\n",
      "[53]\ttrain-logloss:0.07196\teval-logloss:0.26760\n",
      "[54]\ttrain-logloss:0.07021\teval-logloss:0.26661\n",
      "[55]\ttrain-logloss:0.06833\teval-logloss:0.26680\n",
      "[56]\ttrain-logloss:0.06671\teval-logloss:0.26517\n",
      "[57]\ttrain-logloss:0.06519\teval-logloss:0.26412\n",
      "[58]\ttrain-logloss:0.06368\teval-logloss:0.26444\n",
      "[59]\ttrain-logloss:0.06202\teval-logloss:0.26434\n",
      "[60]\ttrain-logloss:0.06048\teval-logloss:0.26208\n",
      "[61]\ttrain-logloss:0.05898\teval-logloss:0.26139\n",
      "[62]\ttrain-logloss:0.05756\teval-logloss:0.26155\n",
      "[63]\ttrain-logloss:0.05614\teval-logloss:0.26114\n",
      "[64]\ttrain-logloss:0.05486\teval-logloss:0.25973\n",
      "[65]\ttrain-logloss:0.05372\teval-logloss:0.25878\n",
      "[66]\ttrain-logloss:0.05263\teval-logloss:0.25758\n",
      "[67]\ttrain-logloss:0.05140\teval-logloss:0.25664\n",
      "[68]\ttrain-logloss:0.05019\teval-logloss:0.25625\n",
      "[69]\ttrain-logloss:0.04910\teval-logloss:0.25593\n",
      "[70]\ttrain-logloss:0.04806\teval-logloss:0.25438\n",
      "[71]\ttrain-logloss:0.04704\teval-logloss:0.25373\n",
      "[72]\ttrain-logloss:0.04606\teval-logloss:0.25411\n",
      "[73]\ttrain-logloss:0.04514\teval-logloss:0.25316\n",
      "[74]\ttrain-logloss:0.04435\teval-logloss:0.25248\n",
      "[75]\ttrain-logloss:0.04347\teval-logloss:0.25271\n",
      "[76]\ttrain-logloss:0.04260\teval-logloss:0.25282\n",
      "[77]\ttrain-logloss:0.04178\teval-logloss:0.25165\n",
      "[78]\ttrain-logloss:0.04099\teval-logloss:0.25181\n",
      "[79]\ttrain-logloss:0.04022\teval-logloss:0.25210\n",
      "[80]\ttrain-logloss:0.03942\teval-logloss:0.25194\n",
      "[81]\ttrain-logloss:0.03875\teval-logloss:0.25254\n",
      "[82]\ttrain-logloss:0.03799\teval-logloss:0.25264\n",
      "[83]\ttrain-logloss:0.03727\teval-logloss:0.25280\n",
      "[84]\ttrain-logloss:0.03657\teval-logloss:0.25281\n",
      "[85]\ttrain-logloss:0.03586\teval-logloss:0.25219\n",
      "[86]\ttrain-logloss:0.03530\teval-logloss:0.25288\n",
      "[87]\ttrain-logloss:0.03464\teval-logloss:0.25226\n",
      "[88]\ttrain-logloss:0.03401\teval-logloss:0.25167\n",
      "[89]\ttrain-logloss:0.03347\teval-logloss:0.25258\n",
      "[90]\ttrain-logloss:0.03297\teval-logloss:0.25331\n",
      "[91]\ttrain-logloss:0.03240\teval-logloss:0.25373\n",
      "[92]\ttrain-logloss:0.03184\teval-logloss:0.25323\n",
      "[93]\ttrain-logloss:0.03136\teval-logloss:0.25240\n",
      "[94]\ttrain-logloss:0.03086\teval-logloss:0.25324\n",
      "[95]\ttrain-logloss:0.03035\teval-logloss:0.25280\n",
      "[96]\ttrain-logloss:0.02985\teval-logloss:0.25215\n",
      "[97]\ttrain-logloss:0.02937\teval-logloss:0.25179\n",
      "[98]\ttrain-logloss:0.02892\teval-logloss:0.25143\n",
      "[99]\ttrain-logloss:0.02853\teval-logloss:0.25180\n",
      "[100]\ttrain-logloss:0.02810\teval-logloss:0.25151\n",
      "[101]\ttrain-logloss:0.02769\teval-logloss:0.25158\n",
      "[102]\ttrain-logloss:0.02729\teval-logloss:0.25130\n",
      "[103]\ttrain-logloss:0.02689\teval-logloss:0.25094\n",
      "[104]\ttrain-logloss:0.02654\teval-logloss:0.25054\n",
      "[105]\ttrain-logloss:0.02617\teval-logloss:0.25030\n",
      "[106]\ttrain-logloss:0.02580\teval-logloss:0.24850\n",
      "[107]\ttrain-logloss:0.02545\teval-logloss:0.24829\n",
      "[108]\ttrain-logloss:0.02509\teval-logloss:0.24828\n",
      "[109]\ttrain-logloss:0.02475\teval-logloss:0.24881\n",
      "[110]\ttrain-logloss:0.02443\teval-logloss:0.24912\n",
      "[111]\ttrain-logloss:0.02405\teval-logloss:0.24791\n",
      "[112]\ttrain-logloss:0.02374\teval-logloss:0.24846\n",
      "[113]\ttrain-logloss:0.02341\teval-logloss:0.24931\n",
      "[114]\ttrain-logloss:0.02314\teval-logloss:0.24832\n",
      "[115]\ttrain-logloss:0.02286\teval-logloss:0.24889\n",
      "[116]\ttrain-logloss:0.02255\teval-logloss:0.24866\n",
      "[117]\ttrain-logloss:0.02227\teval-logloss:0.24925\n",
      "[118]\ttrain-logloss:0.02197\teval-logloss:0.24679\n",
      "[119]\ttrain-logloss:0.02172\teval-logloss:0.24787\n",
      "[120]\ttrain-logloss:0.02141\teval-logloss:0.24846\n",
      "[121]\ttrain-logloss:0.02112\teval-logloss:0.24683\n",
      "[122]\ttrain-logloss:0.02088\teval-logloss:0.24650\n",
      "[123]\ttrain-logloss:0.02061\teval-logloss:0.24497\n",
      "[124]\ttrain-logloss:0.02037\teval-logloss:0.24529\n",
      "[125]\ttrain-logloss:0.02012\teval-logloss:0.24516\n",
      "[126]\ttrain-logloss:0.01987\teval-logloss:0.24576\n",
      "[127]\ttrain-logloss:0.01967\teval-logloss:0.24576\n",
      "[128]\ttrain-logloss:0.01943\teval-logloss:0.24563\n",
      "[129]\ttrain-logloss:0.01922\teval-logloss:0.24533\n",
      "[130]\ttrain-logloss:0.01900\teval-logloss:0.24591\n",
      "[131]\ttrain-logloss:0.01881\teval-logloss:0.24593\n",
      "[132]\ttrain-logloss:0.01858\teval-logloss:0.24582\n",
      "[133]\ttrain-logloss:0.01839\teval-logloss:0.24619\n",
      "[134]\ttrain-logloss:0.01824\teval-logloss:0.24631\n",
      "[135]\ttrain-logloss:0.01805\teval-logloss:0.24669\n",
      "[136]\ttrain-logloss:0.01785\teval-logloss:0.24660\n",
      "[137]\ttrain-logloss:0.01770\teval-logloss:0.24584\n",
      "[138]\ttrain-logloss:0.01753\teval-logloss:0.24465\n",
      "[139]\ttrain-logloss:0.01734\teval-logloss:0.24458\n",
      "[140]\ttrain-logloss:0.01720\teval-logloss:0.24385\n",
      "[141]\ttrain-logloss:0.01703\teval-logloss:0.24422\n",
      "[142]\ttrain-logloss:0.01690\teval-logloss:0.24423\n",
      "[143]\ttrain-logloss:0.01673\teval-logloss:0.24408\n",
      "[144]\ttrain-logloss:0.01655\teval-logloss:0.24381\n",
      "[145]\ttrain-logloss:0.01641\teval-logloss:0.24311\n",
      "[146]\ttrain-logloss:0.01629\teval-logloss:0.24322\n",
      "[147]\ttrain-logloss:0.01614\teval-logloss:0.24360\n",
      "[148]\ttrain-logloss:0.01597\teval-logloss:0.24328\n",
      "[149]\ttrain-logloss:0.01582\teval-logloss:0.24314\n",
      "[150]\ttrain-logloss:0.01571\teval-logloss:0.24315\n",
      "[151]\ttrain-logloss:0.01556\teval-logloss:0.24289\n",
      "[152]\ttrain-logloss:0.01537\teval-logloss:0.24363\n",
      "[153]\ttrain-logloss:0.01523\teval-logloss:0.24404\n",
      "[154]\ttrain-logloss:0.01510\teval-logloss:0.24383\n",
      "[155]\ttrain-logloss:0.01493\teval-logloss:0.24435\n",
      "[156]\ttrain-logloss:0.01478\teval-logloss:0.24425\n",
      "[157]\ttrain-logloss:0.01467\teval-logloss:0.24361\n",
      "[158]\ttrain-logloss:0.01455\teval-logloss:0.24294\n",
      "[159]\ttrain-logloss:0.01440\teval-logloss:0.24340\n",
      "[160]\ttrain-logloss:0.01428\teval-logloss:0.24323\n",
      "[161]\ttrain-logloss:0.01417\teval-logloss:0.24310\n",
      "[162]\ttrain-logloss:0.01409\teval-logloss:0.24247\n",
      "[163]\ttrain-logloss:0.01393\teval-logloss:0.24311\n",
      "[164]\ttrain-logloss:0.01380\teval-logloss:0.24269\n",
      "[165]\ttrain-logloss:0.01368\teval-logloss:0.24268\n",
      "[166]\ttrain-logloss:0.01360\teval-logloss:0.24242\n",
      "[167]\ttrain-logloss:0.01345\teval-logloss:0.24306\n",
      "[168]\ttrain-logloss:0.01335\teval-logloss:0.24220\n",
      "[169]\ttrain-logloss:0.01328\teval-logloss:0.24116\n",
      "[170]\ttrain-logloss:0.01317\teval-logloss:0.24117\n",
      "[171]\ttrain-logloss:0.01308\teval-logloss:0.24126\n",
      "[172]\ttrain-logloss:0.01299\teval-logloss:0.24046\n",
      "[173]\ttrain-logloss:0.01292\teval-logloss:0.23993\n",
      "[174]\ttrain-logloss:0.01284\teval-logloss:0.23985\n",
      "[175]\ttrain-logloss:0.01275\teval-logloss:0.23994\n",
      "[176]\ttrain-logloss:0.01268\teval-logloss:0.23986\n",
      "[177]\ttrain-logloss:0.01260\teval-logloss:0.23996\n",
      "[178]\ttrain-logloss:0.01253\teval-logloss:0.23943\n",
      "[179]\ttrain-logloss:0.01243\teval-logloss:0.23847\n",
      "[180]\ttrain-logloss:0.01236\teval-logloss:0.23842\n",
      "[181]\ttrain-logloss:0.01226\teval-logloss:0.23885\n",
      "[182]\ttrain-logloss:0.01220\teval-logloss:0.23828\n",
      "[183]\ttrain-logloss:0.01214\teval-logloss:0.23892\n",
      "[184]\ttrain-logloss:0.01205\teval-logloss:0.23804\n",
      "[185]\ttrain-logloss:0.01198\teval-logloss:0.23799\n",
      "[186]\ttrain-logloss:0.01191\teval-logloss:0.23809\n",
      "[187]\ttrain-logloss:0.01185\teval-logloss:0.23752\n",
      "[188]\ttrain-logloss:0.01176\teval-logloss:0.23662\n",
      "[189]\ttrain-logloss:0.01170\teval-logloss:0.23659\n",
      "[190]\ttrain-logloss:0.01163\teval-logloss:0.23668\n",
      "[191]\ttrain-logloss:0.01157\teval-logloss:0.23732\n",
      "[192]\ttrain-logloss:0.01152\teval-logloss:0.23726\n",
      "[193]\ttrain-logloss:0.01146\teval-logloss:0.23722\n",
      "[194]\ttrain-logloss:0.01141\teval-logloss:0.23715\n",
      "[195]\ttrain-logloss:0.01136\teval-logloss:0.23661\n",
      "[196]\ttrain-logloss:0.01128\teval-logloss:0.23673\n",
      "[197]\ttrain-logloss:0.01126\teval-logloss:0.23651\n",
      "[198]\ttrain-logloss:0.01120\teval-logloss:0.23628\n",
      "[199]\ttrain-logloss:0.01113\teval-logloss:0.23641\n",
      "[200]\ttrain-logloss:0.01108\teval-logloss:0.23554\n",
      "[201]\ttrain-logloss:0.01103\teval-logloss:0.23533\n",
      "[202]\ttrain-logloss:0.01097\teval-logloss:0.23543\n",
      "[203]\ttrain-logloss:0.01091\teval-logloss:0.23546\n",
      "[204]\ttrain-logloss:0.01086\teval-logloss:0.23588\n",
      "[205]\ttrain-logloss:0.01079\teval-logloss:0.23600\n",
      "[206]\ttrain-logloss:0.01074\teval-logloss:0.23578\n",
      "[207]\ttrain-logloss:0.01069\teval-logloss:0.23597\n",
      "[208]\ttrain-logloss:0.01064\teval-logloss:0.23601\n",
      "[209]\ttrain-logloss:0.01058\teval-logloss:0.23613\n",
      "[210]\ttrain-logloss:0.01054\teval-logloss:0.23592\n",
      "[211]\ttrain-logloss:0.01047\teval-logloss:0.23605\n",
      "[212]\ttrain-logloss:0.01045\teval-logloss:0.23586\n",
      "[213]\ttrain-logloss:0.01041\teval-logloss:0.23626\n",
      "[214]\ttrain-logloss:0.01036\teval-logloss:0.23646\n",
      "[215]\ttrain-logloss:0.01031\teval-logloss:0.23649\n",
      "[216]\ttrain-logloss:0.01026\teval-logloss:0.23697\n",
      "[217]\ttrain-logloss:0.01024\teval-logloss:0.23679\n",
      "[218]\ttrain-logloss:0.01019\teval-logloss:0.23689\n",
      "[219]\ttrain-logloss:0.01014\teval-logloss:0.23693\n",
      "[220]\ttrain-logloss:0.01011\teval-logloss:0.23714\n",
      "[221]\ttrain-logloss:0.01006\teval-logloss:0.23732\n",
      "[222]\ttrain-logloss:0.01004\teval-logloss:0.23714\n",
      "[223]\ttrain-logloss:0.01001\teval-logloss:0.23736\n",
      "[224]\ttrain-logloss:0.00999\teval-logloss:0.23711\n",
      "[225]\ttrain-logloss:0.00997\teval-logloss:0.23703\n",
      "[226]\ttrain-logloss:0.00994\teval-logloss:0.23757\n",
      "[227]\ttrain-logloss:0.00992\teval-logloss:0.23740\n",
      "[228]\ttrain-logloss:0.00986\teval-logloss:0.23673\n",
      "[229]\ttrain-logloss:0.00984\teval-logloss:0.23649\n",
      "[230]\ttrain-logloss:0.00981\teval-logloss:0.23670\n",
      "[231]\ttrain-logloss:0.00979\teval-logloss:0.23653\n",
      "[232]\ttrain-logloss:0.00975\teval-logloss:0.23671\n",
      "[233]\ttrain-logloss:0.00971\teval-logloss:0.23674\n",
      "[234]\ttrain-logloss:0.00968\teval-logloss:0.23696\n",
      "[235]\ttrain-logloss:0.00966\teval-logloss:0.23673\n",
      "[236]\ttrain-logloss:0.00964\teval-logloss:0.23656\n",
      "[237]\ttrain-logloss:0.00961\teval-logloss:0.23708\n",
      "[238]\ttrain-logloss:0.00957\teval-logloss:0.23764\n",
      "[239]\ttrain-logloss:0.00954\teval-logloss:0.23766\n",
      "[240]\ttrain-logloss:0.00949\teval-logloss:0.23778\n",
      "[241]\ttrain-logloss:0.00948\teval-logloss:0.23775\n",
      "[242]\ttrain-logloss:0.00945\teval-logloss:0.23796\n",
      "[243]\ttrain-logloss:0.00943\teval-logloss:0.23780\n",
      "[244]\ttrain-logloss:0.00941\teval-logloss:0.23827\n",
      "[245]\ttrain-logloss:0.00940\teval-logloss:0.23819\n",
      "[246]\ttrain-logloss:0.00937\teval-logloss:0.23840\n",
      "[247]\ttrain-logloss:0.00935\teval-logloss:0.23838\n",
      "[248]\ttrain-logloss:0.00933\teval-logloss:0.23821\n",
      "[249]\ttrain-logloss:0.00931\teval-logloss:0.23872\n",
      "[250]\ttrain-logloss:0.00925\teval-logloss:0.23805\n",
      "[251]\ttrain-logloss:0.00924\teval-logloss:0.23783\n"
     ]
    }
   ],
   "source": [
    "# 학습 데이터 셋은 'train' 평가데이터 셋은 'eval'로 명기\n",
    "eval_list = [(dtr, 'train'),(dval, 'eval')]\n",
    "\n",
    "# 하이퍼 파라미터와 early stopping파라미터를 train()함수의 파라미터로 전달\n",
    "xgb_model = xgb.train(params=params, dtrain=dtr, num_boost_round=num_rounds, early_stopping_rounds=50, evals=eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨\n",
      "[0.938 0.004 0.75  0.049 0.98  1.    0.999 0.999 0.998 0.001]\n",
      "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "pred_probs = xgb_model.predict(dtest)\n",
    "print('predict() 수행 결과값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
    "print(np.round(pred_probs[:10],3))\n",
    "\n",
    "# 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측값 결정하여 List 객체인 preds에 저장\n",
    "preds = [1 if x>0.5 else 0 for x in pred_probs]\n",
    "print('예측값 10개만 표시:', preds[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM(LGBMClassifier)\n",
    "\n",
    "|파라미터|설명|\n",
    "|--|--|\n",
    "|num_leaves|개별 트리가 가질 수 있는 최대 리프의 개수|\n",
    "|min_child_samples|min_data_in_leaf|\n",
    "|max_depth||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 251, number of negative: 158\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4092\n",
      "[LightGBM] [Info] Number of data points in the train set: 409, number of used features: 30\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.613692 -> initscore=0.462858\n",
      "[LightGBM] [Info] Start training from score 0.462858\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "cancer_df['target'] = dataset.target\n",
    "x_features = cancer_df.iloc[:,:-1]\n",
    "y_label = cancer_df.iloc[:,-1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%sms 테스트용 데이터 추출\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_label, test_size=0.2, random_state=156)\n",
    "\n",
    "# 위에서 만든 x_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=156)\n",
    "\n",
    "# 앞서 XGBoost와 동일하게 n_estimators는 400설정\n",
    "lgbm_wrapper = LGBMClassifier(n_estimators=400, learning_rate=0.05)\n",
    "\n",
    "# LightGBM도 XGBoost와 동일하게 조기 중단 수행 가능.\n",
    "evals = [(x_tr, y_tr), (x_val, y_val)]\n",
    "lgbm_wrapper.fit(x_tr, y_tr,  eval_metric='logloss', eval_set=evals)\n",
    "preds = lgbm_wrapper.predict(x_test)\n",
    "pred_proba = lgbm_wrapper.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 베이지안 최적화 기반의 HyperOpt를 이용한 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperopt\n",
      "  Downloading hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "     ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "     -------- ------------------------------- 0.3/1.6 MB 9.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 1.5/1.6 MB 16.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.6/1.6 MB 14.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt) (1.11.2)\n",
      "Requirement already satisfied: six in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt) (1.16.0)\n",
      "Collecting networkx>=2.2 (from hyperopt)\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting future (from hyperopt)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ---------------------------------------- 0.0/840.9 kB ? eta -:--:--\n",
      "     ----------------- ------------------- 399.4/840.9 kB 12.6 MB/s eta 0:00:01\n",
      "     ------------------------------------  839.7/840.9 kB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 840.9/840.9 kB 8.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt) (4.66.1)\n",
      "Collecting cloudpickle (from hyperopt)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: py4j in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hanjieun_2\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->hyperopt) (0.4.6)\n",
      "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 0.9/1.6 MB 18.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 14.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 14.9 MB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492070 sha256=2c1544ae82807a3ba27105dba0e3819639b85c704c1386fbdfca21fdfa30ed55\n",
      "  Stored in directory: c:\\users\\hanjieun_2\\appdata\\local\\pip\\cache\\wheels\\bf\\5d\\6a\\2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built future\n",
      "Installing collected packages: networkx, future, cloudpickle, hyperopt\n",
      "Successfully installed cloudpickle-3.0.0 future-0.18.3 hyperopt-0.2.7 networkx-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력값의 검색 공간 설정\n",
    "\n",
    "|파라미터|설명|\n",
    "|--|--|\n",
    "|hp.quniform(label, low, high, q)|검색공간 설정 low최솟값, high최댓값, q간격|\n",
    "|hp.uniform(label, low, high)|최솟값low에서 최댓값high까지 정규 분포 형태의 검색 공간 설정|\n",
    "|hp.randint(label, upper)|0부터 최댓값upper까지 random한 정숫값으로 검색 공간 설정|\n",
    "|hp.loguniform(label, low, high)|exp(uniform(low, high))값을 반환하며 반환값의 log변환된 값은 정규 분포 형태를 가지는 검색 공간 설정|\n",
    "|hp.choice(label, options)|검색값이 문자열 또는 문자열과 숫자값이 섞여 있을 경우 설정. Options는 리스트나 튜플 형태로 제공되며 hp.choice('tree_criterion'.['gini','entropy])과 같이 설정하면 입력변수 tree_criterion의 값을 'gini'와 'entropy'로 설정하여 입력함|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -10~ 10까지 1간격을 가지는 입력변수 x와 -15~15까지 1간격으로 입력변수 y 설정\n",
    "search_space = {'x':hp.quniform('x', -10, 10, 1), 'y':hp.quniform('y', -15, 15, 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 목적함수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적함수를 생성. 변숫값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정 값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 베이지안 최적화 기법 수행\n",
    "\n",
    "|파라미터|설명|\n",
    "|--|--|\n",
    "|fn|목적함수|\n",
    "|space|검색 공간 딕셔너리|\n",
    "|algo|베이지안 최적화 적용 알고리즘(default=tpe.suggest)|\n",
    "|max_evals|최적 입려값을 찾기 위한 입력값 시도횟수|\n",
    "|trials|최적 입력값을 찾기 위해 시도한 입력값 및 해당 입력값의 목적 함수 반환값 결과를 저장하는데 사용. |\n",
    "|rstate|fmin()을 수행할 때마다 동일한 결과값을 가질 수 있도록 설정하는 랜덤 시드(seed)값(일반적으로 적용하지 않는다.)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 413.16trial/s, best loss: -224.0]\n"
     ]
    }
   ],
   "source": [
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5, trials=trial_val, rstate=np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "print('best', best_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 1278.28trial/s, best loss: -296.0]\n"
     ]
    }
   ],
   "source": [
    "# 입력 결괏값을 저장한 Trials 객체값 생성.\n",
    "trial_val = Trials()\n",
    "\n",
    "# 목적 함수의 최솟값을 반환하는 최적 입력 변숫값을 5번의 입력값 시도(max_evals=5)로 찾아냄.\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20, trials=trial_val, rstate=np.random.default_rng(seed=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "print('best', best_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 함수 반환값 확인해보기 (loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'loss': -64.0, 'status': 'ok'}, {'loss': -184.0, 'status': 'ok'}, {'loss': 56.0, 'status': 'ok'}, {'loss': -224.0, 'status': 'ok'}, {'loss': 61.0, 'status': 'ok'}, {'loss': -296.0, 'status': 'ok'}, {'loss': -40.0, 'status': 'ok'}, {'loss': 281.0, 'status': 'ok'}, {'loss': 64.0, 'status': 'ok'}, {'loss': 100.0, 'status': 'ok'}, {'loss': 60.0, 'status': 'ok'}, {'loss': -39.0, 'status': 'ok'}, {'loss': 1.0, 'status': 'ok'}, {'loss': -164.0, 'status': 'ok'}, {'loss': 21.0, 'status': 'ok'}, {'loss': -56.0, 'status': 'ok'}, {'loss': 284.0, 'status': 'ok'}, {'loss': 176.0, 'status': 'ok'}, {'loss': -171.0, 'status': 'ok'}, {'loss': 0.0, 'status': 'ok'}]\n"
     ]
    }
   ],
   "source": [
    "# fmin()에 인자로 들어가는 Trials객체의 result 속성에 파이썬 리스트로 목적 함수 반환값들이 저장됨.\n",
    "# 리스트 내부의 개별 원소는 {'loss':함수 반환값, 'status':반환 상태값}와 같은 딕셔너리임. \n",
    "print(trial_val.results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력변수명 확인해보기 (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': [-6.0, -4.0, 4.0, -4.0, 9.0, 2.0, 10.0, -9.0, -8.0, -0.0, -0.0, 1.0, 9.0, 6.0, 9.0, 2.0, -2.0, -4.0, 7.0, -0.0], 'y': [5.0, 10.0, -2.0, 12.0, 1.0, 15.0, 7.0, -10.0, 0.0, -5.0, -3.0, 2.0, 4.0, 10.0, 3.0, 3.0, -14.0, -8.0, 11.0, -0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Trials 객체의 vals 속성에 {'입력변수명':개별 수행 시마다 입력되 값 리스트} 형태로 저장됨.\n",
    "print(trial_val.vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 데이터프레임으로 만들어서 직관적으로 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>losses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-296.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-9.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-164.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       x     y  losses\n",
       "0   -6.0   5.0   -64.0\n",
       "1   -4.0  10.0  -184.0\n",
       "2    4.0  -2.0    56.0\n",
       "3   -4.0  12.0  -224.0\n",
       "4    9.0   1.0    61.0\n",
       "5    2.0  15.0  -296.0\n",
       "6   10.0   7.0   -40.0\n",
       "7   -9.0 -10.0   281.0\n",
       "8   -8.0   0.0    64.0\n",
       "9   -0.0  -5.0   100.0\n",
       "10  -0.0  -3.0    60.0\n",
       "11   1.0   2.0   -39.0\n",
       "12   9.0   4.0     1.0\n",
       "13   6.0  10.0  -164.0\n",
       "14   9.0   3.0    21.0\n",
       "15   2.0   3.0   -56.0\n",
       "16  -2.0 -14.0   284.0\n",
       "17  -4.0  -8.0   176.0\n",
       "18   7.0  11.0  -171.0\n",
       "19  -0.0  -0.0     0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results에서 loss 키값에 해당하는 밸류들을 추출하여 list로 생성.\n",
    "losses = [loss_dict['loss'] for loss_dict in trial_val.results]\n",
    "\n",
    "# DataFrame 생성.\n",
    "result_df = pd.DataFrame({'x':trial_val.vals['x'], 'y':trial_val.vals['y'], 'losses':losses})\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 실습 - HyperOpt를 이용한 XGBoost 하이퍼 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_breast_cancer()\n",
    "\n",
    "cancer_df = pd.DataFrame(data=dataset.data, columns=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
       "0          17.99         10.38  ...          0.4601                  0.11890\n",
       "1          20.57         17.77  ...          0.2750                  0.08902\n",
       "2          19.69         21.25  ...          0.3613                  0.08758\n",
       "3          11.42         20.38  ...          0.6638                  0.17300\n",
       "4          20.29         14.34  ...          0.2364                  0.07678\n",
       "..           ...           ...  ...             ...                      ...\n",
       "564        21.56         22.39  ...          0.2060                  0.07115\n",
       "565        20.13         28.25  ...          0.2572                  0.06637\n",
       "566        16.60         28.08  ...          0.2218                  0.07820\n",
       "567        20.60         29.33  ...          0.4087                  0.12400\n",
       "568         7.76         24.54  ...          0.2871                  0.07039\n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error', 'fractal dimension error',\n",
       "       'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
       "       'worst smoothness', 'worst compactness', 'worst concavity',\n",
       "       'worst concave points', 'worst symmetry', 'worst fractal dimension'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_df['target'] = dataset.target\n",
    "x_features = cancer_df.iloc[:,:-1]\n",
    "y_label = cancer_df.iloc[:,-1]\n",
    "\n",
    "# 전체 데이터 중 80%는 학습용 데이터, 20%sms 테스트용 데이터 추출\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_features, y_label, test_size=0.2, random_state=156)\n",
    "\n",
    "# 위에서 만든 x_train, y_train을 다시 쪼개서 90%는 학습과 10%는 검증용 데이터로 분리\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=156)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 공간설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth는 5에서 20까지 1간격으로, min_child_weight는 1에서 2까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색.\n",
    "xgb_search_space = {'max_depth':hp.quniform('max_depth', 5, 20, 1),\n",
    "                    'min_child_weight':hp.quniform('min_child_weight', 1,2,1),\n",
    "                     'learning_rate':hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                      'colsample_bytree':hp.uniform('colsample_bytree', 0.5,1) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 입력변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임.\n",
    "# XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야 함.\n",
    "# 정확도가 높을수록 더 좋은 수치임. -1 * 정확도를 곱해서 큰 정확도일수록 최소가 되도록 변환.\n",
    "def objective_func(search_space):\n",
    "    # 수행시간 절약을 위해 n_estimators는 100으로 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            learning_rate = search_space['learning_rate'],\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            eval_metric='logloss')\n",
    "    accuracy = cross_val_score(xgb_clf, x_train, y_train, scoring='accuracy', cv=3)\n",
    "\n",
    "    # accuracy는 cv=3개수만큼 roc_auc결과를 리스트로 가짐. 이를 평균해서 반환하되 -1을 곱함.\n",
    "    return {'loss':-1 * np.mean(accuracy), 'status':STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fmin()을 이용해 최적 하이퍼 파라미터 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:09<00:00,  5.20trial/s, best loss: -0.9670616939700244]\n",
      "best: {'colsample_bytree': 0.684441779397407, 'learning_rate': 0.1475201153968472, 'max_depth': 9.0, 'min_child_weight': 2.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "best = fmin(fn=objective_func, space=xgb_search_space, algo=tpe.suggest, max_evals=50, \n",
    "            trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 최적 하이퍼파라미터를 이용해 XGBClassifier 재학습 후 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-logloss:0.55271\tvalidation_1-logloss:0.58669\n",
      "[1]\tvalidation_0-logloss:0.46532\tvalidation_1-logloss:0.52479\n",
      "[2]\tvalidation_0-logloss:0.39616\tvalidation_1-logloss:0.46923\n",
      "[3]\tvalidation_0-logloss:0.34165\tvalidation_1-logloss:0.42858\n",
      "[4]\tvalidation_0-logloss:0.29745\tvalidation_1-logloss:0.39483\n",
      "[5]\tvalidation_0-logloss:0.25934\tvalidation_1-logloss:0.36657\n",
      "[6]\tvalidation_0-logloss:0.22862\tvalidation_1-logloss:0.35072\n",
      "[7]\tvalidation_0-logloss:0.20367\tvalidation_1-logloss:0.33159\n",
      "[8]\tvalidation_0-logloss:0.18239\tvalidation_1-logloss:0.32347\n",
      "[9]\tvalidation_0-logloss:0.16291\tvalidation_1-logloss:0.30890\n",
      "[10]\tvalidation_0-logloss:0.14780\tvalidation_1-logloss:0.30568\n",
      "[11]\tvalidation_0-logloss:0.13390\tvalidation_1-logloss:0.29906\n",
      "[12]\tvalidation_0-logloss:0.12276\tvalidation_1-logloss:0.28876\n",
      "[13]\tvalidation_0-logloss:0.11289\tvalidation_1-logloss:0.28343\n",
      "[14]\tvalidation_0-logloss:0.10346\tvalidation_1-logloss:0.27987\n",
      "[15]\tvalidation_0-logloss:0.09554\tvalidation_1-logloss:0.27622\n",
      "[16]\tvalidation_0-logloss:0.08826\tvalidation_1-logloss:0.27372\n",
      "[17]\tvalidation_0-logloss:0.08247\tvalidation_1-logloss:0.27294\n",
      "[18]\tvalidation_0-logloss:0.07739\tvalidation_1-logloss:0.26674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19]\tvalidation_0-logloss:0.07293\tvalidation_1-logloss:0.26352\n",
      "[20]\tvalidation_0-logloss:0.06751\tvalidation_1-logloss:0.26310\n",
      "[21]\tvalidation_0-logloss:0.06306\tvalidation_1-logloss:0.25711\n",
      "[22]\tvalidation_0-logloss:0.05846\tvalidation_1-logloss:0.25678\n",
      "[23]\tvalidation_0-logloss:0.05452\tvalidation_1-logloss:0.25732\n",
      "[24]\tvalidation_0-logloss:0.05132\tvalidation_1-logloss:0.25525\n",
      "[25]\tvalidation_0-logloss:0.04834\tvalidation_1-logloss:0.25395\n",
      "[26]\tvalidation_0-logloss:0.04550\tvalidation_1-logloss:0.25433\n",
      "[27]\tvalidation_0-logloss:0.04313\tvalidation_1-logloss:0.25181\n",
      "[28]\tvalidation_0-logloss:0.04134\tvalidation_1-logloss:0.25446\n",
      "[29]\tvalidation_0-logloss:0.03934\tvalidation_1-logloss:0.25551\n",
      "[30]\tvalidation_0-logloss:0.03736\tvalidation_1-logloss:0.25798\n",
      "[31]\tvalidation_0-logloss:0.03579\tvalidation_1-logloss:0.25839\n",
      "[32]\tvalidation_0-logloss:0.03441\tvalidation_1-logloss:0.25869\n",
      "[33]\tvalidation_0-logloss:0.03305\tvalidation_1-logloss:0.26211\n",
      "[34]\tvalidation_0-logloss:0.03201\tvalidation_1-logloss:0.26126\n",
      "[35]\tvalidation_0-logloss:0.03106\tvalidation_1-logloss:0.26290\n",
      "[36]\tvalidation_0-logloss:0.03012\tvalidation_1-logloss:0.26363\n",
      "[37]\tvalidation_0-logloss:0.02941\tvalidation_1-logloss:0.26196\n",
      "[38]\tvalidation_0-logloss:0.02882\tvalidation_1-logloss:0.26225\n",
      "[39]\tvalidation_0-logloss:0.02817\tvalidation_1-logloss:0.26081\n",
      "[40]\tvalidation_0-logloss:0.02744\tvalidation_1-logloss:0.26035\n",
      "[41]\tvalidation_0-logloss:0.02672\tvalidation_1-logloss:0.26134\n",
      "[42]\tvalidation_0-logloss:0.02617\tvalidation_1-logloss:0.25945\n",
      "[43]\tvalidation_0-logloss:0.02571\tvalidation_1-logloss:0.25466\n",
      "[44]\tvalidation_0-logloss:0.02529\tvalidation_1-logloss:0.25783\n",
      "[45]\tvalidation_0-logloss:0.02503\tvalidation_1-logloss:0.25761\n",
      "[46]\tvalidation_0-logloss:0.02461\tvalidation_1-logloss:0.25833\n",
      "[47]\tvalidation_0-logloss:0.02410\tvalidation_1-logloss:0.25943\n",
      "[48]\tvalidation_0-logloss:0.02376\tvalidation_1-logloss:0.26181\n",
      "[49]\tvalidation_0-logloss:0.02356\tvalidation_1-logloss:0.26174\n",
      "[50]\tvalidation_0-logloss:0.02298\tvalidation_1-logloss:0.25764\n",
      "[51]\tvalidation_0-logloss:0.02279\tvalidation_1-logloss:0.25746\n",
      "[52]\tvalidation_0-logloss:0.02246\tvalidation_1-logloss:0.25602\n",
      "[53]\tvalidation_0-logloss:0.02230\tvalidation_1-logloss:0.25588\n",
      "[54]\tvalidation_0-logloss:0.02212\tvalidation_1-logloss:0.25788\n",
      "[55]\tvalidation_0-logloss:0.02170\tvalidation_1-logloss:0.25873\n",
      "[56]\tvalidation_0-logloss:0.02154\tvalidation_1-logloss:0.25844\n",
      "[57]\tvalidation_0-logloss:0.02141\tvalidation_1-logloss:0.25723\n",
      "[58]\tvalidation_0-logloss:0.02123\tvalidation_1-logloss:0.25924\n",
      "[59]\tvalidation_0-logloss:0.02110\tvalidation_1-logloss:0.26106\n",
      "[60]\tvalidation_0-logloss:0.02096\tvalidation_1-logloss:0.26231\n",
      "[61]\tvalidation_0-logloss:0.02083\tvalidation_1-logloss:0.26113\n",
      "[62]\tvalidation_0-logloss:0.02070\tvalidation_1-logloss:0.26108\n",
      "[63]\tvalidation_0-logloss:0.02058\tvalidation_1-logloss:0.26102\n",
      "[64]\tvalidation_0-logloss:0.02045\tvalidation_1-logloss:0.26285\n",
      "[65]\tvalidation_0-logloss:0.02033\tvalidation_1-logloss:0.26256\n",
      "[66]\tvalidation_0-logloss:0.02022\tvalidation_1-logloss:0.25985\n",
      "[67]\tvalidation_0-logloss:0.02010\tvalidation_1-logloss:0.26161\n",
      "[68]\tvalidation_0-logloss:0.01998\tvalidation_1-logloss:0.26049\n",
      "[69]\tvalidation_0-logloss:0.01987\tvalidation_1-logloss:0.26093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanjieun_2\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\sklearn.py:885: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70]\tvalidation_0-logloss:0.01977\tvalidation_1-logloss:0.25877\n",
      "[71]\tvalidation_0-logloss:0.01966\tvalidation_1-logloss:0.26048\n",
      "[72]\tvalidation_0-logloss:0.01956\tvalidation_1-logloss:0.26022\n",
      "[73]\tvalidation_0-logloss:0.01945\tvalidation_1-logloss:0.25763\n",
      "[74]\tvalidation_0-logloss:0.01935\tvalidation_1-logloss:0.25927\n",
      "[75]\tvalidation_0-logloss:0.01926\tvalidation_1-logloss:0.25970\n",
      "[76]\tvalidation_0-logloss:0.01915\tvalidation_1-logloss:0.25861\n",
      "[77]\tvalidation_0-logloss:0.01906\tvalidation_1-logloss:0.25966\n",
      "[78]\tvalidation_0-logloss:0.01896\tvalidation_1-logloss:0.25713\n",
      "[79]\tvalidation_0-logloss:0.01888\tvalidation_1-logloss:0.25692\n",
      "[80]\tvalidation_0-logloss:0.01878\tvalidation_1-logloss:0.25861\n",
      "[81]\tvalidation_0-logloss:0.01869\tvalidation_1-logloss:0.25765\n",
      "[82]\tvalidation_0-logloss:0.01860\tvalidation_1-logloss:0.25761\n",
      "[83]\tvalidation_0-logloss:0.01851\tvalidation_1-logloss:0.25923\n",
      "[84]\tvalidation_0-logloss:0.01843\tvalidation_1-logloss:0.25832\n",
      "[85]\tvalidation_0-logloss:0.01835\tvalidation_1-logloss:0.26011\n",
      "[86]\tvalidation_0-logloss:0.01826\tvalidation_1-logloss:0.25812\n",
      "[87]\tvalidation_0-logloss:0.01818\tvalidation_1-logloss:0.25689\n",
      "[88]\tvalidation_0-logloss:0.01810\tvalidation_1-logloss:0.25730\n",
      "[89]\tvalidation_0-logloss:0.01802\tvalidation_1-logloss:0.25726\n",
      "[90]\tvalidation_0-logloss:0.01794\tvalidation_1-logloss:0.25496\n",
      "[91]\tvalidation_0-logloss:0.01786\tvalidation_1-logloss:0.25654\n",
      "[92]\tvalidation_0-logloss:0.01778\tvalidation_1-logloss:0.25629\n",
      "[93]\tvalidation_0-logloss:0.01770\tvalidation_1-logloss:0.25511\n",
      "[94]\tvalidation_0-logloss:0.01763\tvalidation_1-logloss:0.25491\n",
      "[95]\tvalidation_0-logloss:0.01756\tvalidation_1-logloss:0.25280\n",
      "[96]\tvalidation_0-logloss:0.01749\tvalidation_1-logloss:0.25269\n",
      "[97]\tvalidation_0-logloss:0.01743\tvalidation_1-logloss:0.25435\n",
      "[98]\tvalidation_0-logloss:0.01736\tvalidation_1-logloss:0.25230\n",
      "[99]\tvalidation_0-logloss:0.01729\tvalidation_1-logloss:0.25317\n",
      "[100]\tvalidation_0-logloss:0.01722\tvalidation_1-logloss:0.25238\n",
      "[101]\tvalidation_0-logloss:0.01716\tvalidation_1-logloss:0.25228\n",
      "[102]\tvalidation_0-logloss:0.01709\tvalidation_1-logloss:0.25171\n",
      "[103]\tvalidation_0-logloss:0.01703\tvalidation_1-logloss:0.25152\n",
      "[104]\tvalidation_0-logloss:0.01697\tvalidation_1-logloss:0.24952\n",
      "[105]\tvalidation_0-logloss:0.01691\tvalidation_1-logloss:0.25114\n",
      "[106]\tvalidation_0-logloss:0.01684\tvalidation_1-logloss:0.25107\n",
      "[107]\tvalidation_0-logloss:0.01678\tvalidation_1-logloss:0.25116\n",
      "[108]\tvalidation_0-logloss:0.01673\tvalidation_1-logloss:0.24944\n",
      "[109]\tvalidation_0-logloss:0.01667\tvalidation_1-logloss:0.24754\n",
      "[110]\tvalidation_0-logloss:0.01661\tvalidation_1-logloss:0.24910\n",
      "[111]\tvalidation_0-logloss:0.01656\tvalidation_1-logloss:0.24903\n",
      "[112]\tvalidation_0-logloss:0.01650\tvalidation_1-logloss:0.24831\n",
      "[113]\tvalidation_0-logloss:0.01645\tvalidation_1-logloss:0.24972\n",
      "[114]\tvalidation_0-logloss:0.01639\tvalidation_1-logloss:0.24965\n",
      "[115]\tvalidation_0-logloss:0.01634\tvalidation_1-logloss:0.24896\n",
      "[116]\tvalidation_0-logloss:0.01629\tvalidation_1-logloss:0.24718\n",
      "[117]\tvalidation_0-logloss:0.01623\tvalidation_1-logloss:0.24732\n",
      "[118]\tvalidation_0-logloss:0.01618\tvalidation_1-logloss:0.24793\n",
      "[119]\tvalidation_0-logloss:0.01612\tvalidation_1-logloss:0.24771\n",
      "[120]\tvalidation_0-logloss:0.01608\tvalidation_1-logloss:0.24690\n",
      "[121]\tvalidation_0-logloss:0.01603\tvalidation_1-logloss:0.24644\n",
      "[122]\tvalidation_0-logloss:0.01598\tvalidation_1-logloss:0.24640\n",
      "[123]\tvalidation_0-logloss:0.01593\tvalidation_1-logloss:0.24632\n",
      "[124]\tvalidation_0-logloss:0.01588\tvalidation_1-logloss:0.24692\n",
      "[125]\tvalidation_0-logloss:0.01584\tvalidation_1-logloss:0.24673\n",
      "[126]\tvalidation_0-logloss:0.01579\tvalidation_1-logloss:0.24496\n",
      "[127]\tvalidation_0-logloss:0.01574\tvalidation_1-logloss:0.24512\n",
      "[128]\tvalidation_0-logloss:0.01569\tvalidation_1-logloss:0.24662\n",
      "[129]\tvalidation_0-logloss:0.01564\tvalidation_1-logloss:0.24490\n",
      "[130]\tvalidation_0-logloss:0.01560\tvalidation_1-logloss:0.24431\n",
      "[131]\tvalidation_0-logloss:0.01556\tvalidation_1-logloss:0.24448\n",
      "[132]\tvalidation_0-logloss:0.01551\tvalidation_1-logloss:0.24510\n",
      "[133]\tvalidation_0-logloss:0.01547\tvalidation_1-logloss:0.24500\n",
      "[134]\tvalidation_0-logloss:0.01543\tvalidation_1-logloss:0.24342\n",
      "[135]\tvalidation_0-logloss:0.01538\tvalidation_1-logloss:0.24484\n",
      "[136]\tvalidation_0-logloss:0.01534\tvalidation_1-logloss:0.24464\n",
      "[137]\tvalidation_0-logloss:0.01530\tvalidation_1-logloss:0.24420\n",
      "[138]\tvalidation_0-logloss:0.01526\tvalidation_1-logloss:0.24438\n",
      "[139]\tvalidation_0-logloss:0.01522\tvalidation_1-logloss:0.24382\n",
      "[140]\tvalidation_0-logloss:0.01518\tvalidation_1-logloss:0.24232\n",
      "[141]\tvalidation_0-logloss:0.01514\tvalidation_1-logloss:0.24372\n",
      "[142]\tvalidation_0-logloss:0.01510\tvalidation_1-logloss:0.24433\n",
      "[143]\tvalidation_0-logloss:0.01506\tvalidation_1-logloss:0.24422\n",
      "[144]\tvalidation_0-logloss:0.01502\tvalidation_1-logloss:0.24443\n",
      "[145]\tvalidation_0-logloss:0.01498\tvalidation_1-logloss:0.24293\n",
      "[146]\tvalidation_0-logloss:0.01494\tvalidation_1-logloss:0.24314\n",
      "[147]\tvalidation_0-logloss:0.01490\tvalidation_1-logloss:0.24271\n",
      "[148]\tvalidation_0-logloss:0.01487\tvalidation_1-logloss:0.24403\n",
      "[149]\tvalidation_0-logloss:0.01483\tvalidation_1-logloss:0.24350\n",
      "[150]\tvalidation_0-logloss:0.01479\tvalidation_1-logloss:0.24410\n",
      "[151]\tvalidation_0-logloss:0.01476\tvalidation_1-logloss:0.24464\n",
      "[152]\tvalidation_0-logloss:0.01473\tvalidation_1-logloss:0.24483\n",
      "[153]\tvalidation_0-logloss:0.01469\tvalidation_1-logloss:0.24337\n",
      "[154]\tvalidation_0-logloss:0.01465\tvalidation_1-logloss:0.24325\n",
      "[155]\tvalidation_0-logloss:0.01462\tvalidation_1-logloss:0.24348\n",
      "[156]\tvalidation_0-logloss:0.01458\tvalidation_1-logloss:0.24305\n",
      "[157]\tvalidation_0-logloss:0.01455\tvalidation_1-logloss:0.24254\n",
      "[158]\tvalidation_0-logloss:0.01452\tvalidation_1-logloss:0.24276\n",
      "[159]\tvalidation_0-logloss:0.01448\tvalidation_1-logloss:0.24140\n",
      "[160]\tvalidation_0-logloss:0.01445\tvalidation_1-logloss:0.24268\n",
      "[161]\tvalidation_0-logloss:0.01442\tvalidation_1-logloss:0.24256\n",
      "[162]\tvalidation_0-logloss:0.01439\tvalidation_1-logloss:0.24275\n",
      "[163]\tvalidation_0-logloss:0.01436\tvalidation_1-logloss:0.24235\n",
      "[164]\tvalidation_0-logloss:0.01433\tvalidation_1-logloss:0.24296\n",
      "[165]\tvalidation_0-logloss:0.01430\tvalidation_1-logloss:0.24167\n",
      "[166]\tvalidation_0-logloss:0.01426\tvalidation_1-logloss:0.24192\n",
      "[167]\tvalidation_0-logloss:0.01423\tvalidation_1-logloss:0.24144\n",
      "[168]\tvalidation_0-logloss:0.01420\tvalidation_1-logloss:0.24268\n",
      "[169]\tvalidation_0-logloss:0.01417\tvalidation_1-logloss:0.24256\n",
      "[170]\tvalidation_0-logloss:0.01414\tvalidation_1-logloss:0.24313\n",
      "[171]\tvalidation_0-logloss:0.01412\tvalidation_1-logloss:0.24338\n",
      "[172]\tvalidation_0-logloss:0.01409\tvalidation_1-logloss:0.24291\n",
      "[173]\tvalidation_0-logloss:0.01406\tvalidation_1-logloss:0.24279\n",
      "[174]\tvalidation_0-logloss:0.01403\tvalidation_1-logloss:0.24236\n",
      "[175]\tvalidation_0-logloss:0.01401\tvalidation_1-logloss:0.24199\n",
      "[176]\tvalidation_0-logloss:0.01398\tvalidation_1-logloss:0.24316\n",
      "[177]\tvalidation_0-logloss:0.01395\tvalidation_1-logloss:0.24371\n",
      "[178]\tvalidation_0-logloss:0.01393\tvalidation_1-logloss:0.24360\n",
      "[179]\tvalidation_0-logloss:0.01390\tvalidation_1-logloss:0.24386\n",
      "[180]\tvalidation_0-logloss:0.01388\tvalidation_1-logloss:0.24344\n",
      "[181]\tvalidation_0-logloss:0.01385\tvalidation_1-logloss:0.24295\n",
      "[182]\tvalidation_0-logloss:0.01383\tvalidation_1-logloss:0.24284\n",
      "[183]\tvalidation_0-logloss:0.01380\tvalidation_1-logloss:0.24311\n",
      "[184]\tvalidation_0-logloss:0.01378\tvalidation_1-logloss:0.24367\n",
      "[185]\tvalidation_0-logloss:0.01376\tvalidation_1-logloss:0.24327\n",
      "[186]\tvalidation_0-logloss:0.01373\tvalidation_1-logloss:0.24316\n",
      "[187]\tvalidation_0-logloss:0.01371\tvalidation_1-logloss:0.24426\n",
      "[188]\tvalidation_0-logloss:0.01369\tvalidation_1-logloss:0.24452\n",
      "[189]\tvalidation_0-logloss:0.01366\tvalidation_1-logloss:0.24404\n",
      "[190]\tvalidation_0-logloss:0.01364\tvalidation_1-logloss:0.24368\n",
      "[191]\tvalidation_0-logloss:0.01362\tvalidation_1-logloss:0.24332\n",
      "[192]\tvalidation_0-logloss:0.01360\tvalidation_1-logloss:0.24322\n",
      "[193]\tvalidation_0-logloss:0.01358\tvalidation_1-logloss:0.24279\n",
      "[194]\tvalidation_0-logloss:0.01355\tvalidation_1-logloss:0.24307\n",
      "[195]\tvalidation_0-logloss:0.01353\tvalidation_1-logloss:0.24413\n",
      "[196]\tvalidation_0-logloss:0.01351\tvalidation_1-logloss:0.24379\n",
      "[197]\tvalidation_0-logloss:0.01349\tvalidation_1-logloss:0.24432\n",
      "[198]\tvalidation_0-logloss:0.01347\tvalidation_1-logloss:0.24400\n",
      "[199]\tvalidation_0-logloss:0.01346\tvalidation_1-logloss:0.24449\n",
      "[200]\tvalidation_0-logloss:0.01343\tvalidation_1-logloss:0.24438\n",
      "[201]\tvalidation_0-logloss:0.01342\tvalidation_1-logloss:0.24463\n",
      "[202]\tvalidation_0-logloss:0.01340\tvalidation_1-logloss:0.24454\n",
      "[203]\tvalidation_0-logloss:0.01338\tvalidation_1-logloss:0.24412\n",
      "[204]\tvalidation_0-logloss:0.01336\tvalidation_1-logloss:0.24388\n",
      "[205]\tvalidation_0-logloss:0.01334\tvalidation_1-logloss:0.24438\n",
      "[206]\tvalidation_0-logloss:0.01333\tvalidation_1-logloss:0.24400\n",
      "[207]\tvalidation_0-logloss:0.01331\tvalidation_1-logloss:0.24409\n",
      "[208]\tvalidation_0-logloss:0.01329\tvalidation_1-logloss:0.24434\n",
      "[209]\tvalidation_0-logloss:0.01328\tvalidation_1-logloss:0.24403\n",
      "[210]\tvalidation_0-logloss:0.01326\tvalidation_1-logloss:0.24396\n",
      "[211]\tvalidation_0-logloss:0.01324\tvalidation_1-logloss:0.24363\n",
      "[212]\tvalidation_0-logloss:0.01323\tvalidation_1-logloss:0.24327\n",
      "[213]\tvalidation_0-logloss:0.01321\tvalidation_1-logloss:0.24335\n",
      "[214]\tvalidation_0-logloss:0.01320\tvalidation_1-logloss:0.24305\n",
      "[215]\tvalidation_0-logloss:0.01318\tvalidation_1-logloss:0.24354\n",
      "[216]\tvalidation_0-logloss:0.01317\tvalidation_1-logloss:0.24331\n",
      "[217]\tvalidation_0-logloss:0.01315\tvalidation_1-logloss:0.24367\n",
      "[218]\tvalidation_0-logloss:0.01314\tvalidation_1-logloss:0.24360\n",
      "[219]\tvalidation_0-logloss:0.01312\tvalidation_1-logloss:0.24406\n",
      "[220]\tvalidation_0-logloss:0.01311\tvalidation_1-logloss:0.24373\n",
      "[221]\tvalidation_0-logloss:0.01310\tvalidation_1-logloss:0.24381\n",
      "[222]\tvalidation_0-logloss:0.01308\tvalidation_1-logloss:0.24359\n",
      "[223]\tvalidation_0-logloss:0.01307\tvalidation_1-logloss:0.24394\n",
      "[224]\tvalidation_0-logloss:0.01306\tvalidation_1-logloss:0.24362\n",
      "[225]\tvalidation_0-logloss:0.01305\tvalidation_1-logloss:0.24336\n",
      "[226]\tvalidation_0-logloss:0.01303\tvalidation_1-logloss:0.24343\n",
      "[227]\tvalidation_0-logloss:0.01302\tvalidation_1-logloss:0.24376\n",
      "[228]\tvalidation_0-logloss:0.01301\tvalidation_1-logloss:0.24397\n",
      "[229]\tvalidation_0-logloss:0.01300\tvalidation_1-logloss:0.24371\n",
      "[230]\tvalidation_0-logloss:0.01299\tvalidation_1-logloss:0.24406\n",
      "[231]\tvalidation_0-logloss:0.01298\tvalidation_1-logloss:0.24375\n",
      "[232]\tvalidation_0-logloss:0.01297\tvalidation_1-logloss:0.24382\n",
      "[233]\tvalidation_0-logloss:0.01296\tvalidation_1-logloss:0.24357\n",
      "[234]\tvalidation_0-logloss:0.01295\tvalidation_1-logloss:0.24398\n",
      "[235]\tvalidation_0-logloss:0.01294\tvalidation_1-logloss:0.24370\n",
      "[236]\tvalidation_0-logloss:0.01293\tvalidation_1-logloss:0.24361\n",
      "[237]\tvalidation_0-logloss:0.01292\tvalidation_1-logloss:0.24368\n",
      "[238]\tvalidation_0-logloss:0.01291\tvalidation_1-logloss:0.24341\n",
      "[239]\tvalidation_0-logloss:0.01290\tvalidation_1-logloss:0.24360\n",
      "[240]\tvalidation_0-logloss:0.01289\tvalidation_1-logloss:0.24337\n",
      "[241]\tvalidation_0-logloss:0.01288\tvalidation_1-logloss:0.24328\n",
      "[242]\tvalidation_0-logloss:0.01287\tvalidation_1-logloss:0.24368\n",
      "[243]\tvalidation_0-logloss:0.01286\tvalidation_1-logloss:0.24342\n",
      "[244]\tvalidation_0-logloss:0.01285\tvalidation_1-logloss:0.24373\n",
      "[245]\tvalidation_0-logloss:0.01285\tvalidation_1-logloss:0.24392\n",
      "[246]\tvalidation_0-logloss:0.01284\tvalidation_1-logloss:0.24366\n",
      "[247]\tvalidation_0-logloss:0.01283\tvalidation_1-logloss:0.24344\n",
      "[248]\tvalidation_0-logloss:0.01282\tvalidation_1-logloss:0.24351\n",
      "[249]\tvalidation_0-logloss:0.01281\tvalidation_1-logloss:0.24343\n",
      "[250]\tvalidation_0-logloss:0.01280\tvalidation_1-logloss:0.24379\n",
      "[251]\tvalidation_0-logloss:0.01280\tvalidation_1-logloss:0.24358\n",
      "[252]\tvalidation_0-logloss:0.01279\tvalidation_1-logloss:0.24385\n",
      "[253]\tvalidation_0-logloss:0.01278\tvalidation_1-logloss:0.24401\n",
      "[254]\tvalidation_0-logloss:0.01277\tvalidation_1-logloss:0.24376\n",
      "[255]\tvalidation_0-logloss:0.01277\tvalidation_1-logloss:0.24369\n",
      "[256]\tvalidation_0-logloss:0.01276\tvalidation_1-logloss:0.24362\n",
      "[257]\tvalidation_0-logloss:0.01275\tvalidation_1-logloss:0.24388\n",
      "[258]\tvalidation_0-logloss:0.01274\tvalidation_1-logloss:0.24363\n",
      "[259]\tvalidation_0-logloss:0.01274\tvalidation_1-logloss:0.24392\n",
      "[260]\tvalidation_0-logloss:0.01273\tvalidation_1-logloss:0.24418\n",
      "[261]\tvalidation_0-logloss:0.01272\tvalidation_1-logloss:0.24451\n",
      "[262]\tvalidation_0-logloss:0.01272\tvalidation_1-logloss:0.24427\n",
      "[263]\tvalidation_0-logloss:0.01271\tvalidation_1-logloss:0.24421\n",
      "[264]\tvalidation_0-logloss:0.01270\tvalidation_1-logloss:0.24446\n",
      "[265]\tvalidation_0-logloss:0.01270\tvalidation_1-logloss:0.24440\n",
      "[266]\tvalidation_0-logloss:0.01269\tvalidation_1-logloss:0.24417\n",
      "[267]\tvalidation_0-logloss:0.01268\tvalidation_1-logloss:0.24398\n",
      "[268]\tvalidation_0-logloss:0.01268\tvalidation_1-logloss:0.24422\n",
      "[269]\tvalidation_0-logloss:0.01267\tvalidation_1-logloss:0.24452\n",
      "[270]\tvalidation_0-logloss:0.01267\tvalidation_1-logloss:0.24467\n",
      "[271]\tvalidation_0-logloss:0.01266\tvalidation_1-logloss:0.24445\n",
      "[272]\tvalidation_0-logloss:0.01266\tvalidation_1-logloss:0.24426\n",
      "[273]\tvalidation_0-logloss:0.01265\tvalidation_1-logloss:0.24420\n",
      "[274]\tvalidation_0-logloss:0.01264\tvalidation_1-logloss:0.24434\n",
      "[275]\tvalidation_0-logloss:0.01264\tvalidation_1-logloss:0.24416\n",
      "[276]\tvalidation_0-logloss:0.01263\tvalidation_1-logloss:0.24415\n",
      "[277]\tvalidation_0-logloss:0.01263\tvalidation_1-logloss:0.24428\n",
      "[278]\tvalidation_0-logloss:0.01262\tvalidation_1-logloss:0.24410\n",
      "[279]\tvalidation_0-logloss:0.01262\tvalidation_1-logloss:0.24434\n",
      "[280]\tvalidation_0-logloss:0.01262\tvalidation_1-logloss:0.24434\n",
      "[281]\tvalidation_0-logloss:0.01261\tvalidation_1-logloss:0.24413\n",
      "[282]\tvalidation_0-logloss:0.01261\tvalidation_1-logloss:0.24409\n",
      "[283]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[284]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[285]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[286]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[287]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[288]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[289]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[290]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[291]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[292]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[293]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[294]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[295]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[296]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[297]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[298]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[299]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[300]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[301]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[302]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[303]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[304]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[305]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[306]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[307]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[308]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[309]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[310]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[311]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[312]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[313]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[314]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[315]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[316]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[317]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[318]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[319]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[320]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[321]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[322]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[323]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[324]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[325]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[326]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[327]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[328]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[329]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[330]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[331]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[332]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[333]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[334]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[335]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[336]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[337]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[338]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[339]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[340]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[341]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[342]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[343]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[344]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[345]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[346]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[347]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[348]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[349]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[350]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[351]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[352]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[353]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[354]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[355]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[356]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[357]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[358]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[359]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[360]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[361]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[362]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[363]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[364]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[365]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[366]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[367]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[368]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[369]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[370]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[371]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[372]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[373]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[374]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[375]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[376]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[377]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[378]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[379]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[380]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[381]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[382]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[383]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[384]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[385]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[386]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[387]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[388]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[389]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[390]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[391]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[392]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[393]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[394]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[395]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[396]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[397]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[398]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n",
      "[399]\tvalidation_0-logloss:0.01260\tvalidation_1-logloss:0.24404\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanjieun_2\\Desktop\\개인공부\\머신러닝스터디\\데이터분석가가_반드시_알아야_할_모든것\\3부.데이터분석하기\\13.머신러닝_분석_방법론\\10.앙상블학습.ipynb 셀 73\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanjieun_2/Desktop/%EA%B0%9C%EC%9D%B8%EA%B3%B5%EB%B6%80/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%8A%A4%ED%84%B0%EB%94%94/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B0%80%EA%B0%80_%EB%B0%98%EB%93%9C%EC%8B%9C_%EC%95%8C%EC%95%84%EC%95%BC_%ED%95%A0_%EB%AA%A8%EB%93%A0%EA%B2%83/3%EB%B6%80.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/13.%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%B6%84%EC%84%9D_%EB%B0%A9%EB%B2%95%EB%A1%A0/10.%EC%95%99%EC%83%81%EB%B8%94%ED%95%99%EC%8A%B5.ipynb#Y133sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m xgb_wrapper\u001b[39m.\u001b[39mfit(x_tr, y_tr, eval_metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlogloss\u001b[39m\u001b[39m'\u001b[39m, eval_set\u001b[39m=\u001b[39mevals)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hanjieun_2/Desktop/%EA%B0%9C%EC%9D%B8%EA%B3%B5%EB%B6%80/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%8A%A4%ED%84%B0%EB%94%94/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B0%80%EA%B0%80_%EB%B0%98%EB%93%9C%EC%8B%9C_%EC%95%8C%EC%95%84%EC%95%BC_%ED%95%A0_%EB%AA%A8%EB%93%A0%EA%B2%83/3%EB%B6%80.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/13.%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%B6%84%EC%84%9D_%EB%B0%A9%EB%B2%95%EB%A1%A0/10.%EC%95%99%EC%83%81%EB%B8%94%ED%95%99%EC%8A%B5.ipynb#Y133sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m preds \u001b[39m=\u001b[39m xgb_wrapper\u001b[39m.\u001b[39mpredict(x_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hanjieun_2/Desktop/%EA%B0%9C%EC%9D%B8%EA%B3%B5%EB%B6%80/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D%EC%8A%A4%ED%84%B0%EB%94%94/%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%EA%B0%80%EA%B0%80_%EB%B0%98%EB%93%9C%EC%8B%9C_%EC%95%8C%EC%95%84%EC%95%BC_%ED%95%A0_%EB%AA%A8%EB%93%A0%EA%B2%83/3%EB%B6%80.%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D%ED%95%98%EA%B8%B0/13.%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EB%B6%84%EC%84%9D_%EB%B0%A9%EB%B2%95%EB%A1%A0/10.%EC%95%99%EC%83%81%EB%B8%94%ED%95%99%EC%8A%B5.ipynb#Y133sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pred_proba \u001b[39m=\u001b[39m xgb_wrapper\u001b[39m.\u001b[39;49mpredict(x_test)[:,\u001b[39m1\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "xgb_wrapper = XGBClassifier(n_estimators=400,\n",
    "                            learning_rate=round(best['learning_rate'],5),\n",
    "                            max_depth=int(best['max_depth']),\n",
    "                            min_child_weight=int(best['min_child_weight']),\n",
    "                            colsample_bytree=round(best['colsample_bytree'],5))\n",
    "\n",
    "evals = [(x_tr, y_tr),(x_val, y_val)]\n",
    "xgb_wrapper.fit(x_tr, y_tr, eval_metric='logloss', eval_set=evals)\n",
    "\n",
    "preds = xgb_wrapper.predict(x_test)\n",
    "pred_proba = xgb_wrapper.predict(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
